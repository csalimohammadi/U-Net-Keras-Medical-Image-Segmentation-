{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-07-14T17:42:47.88878Z","iopub.execute_input":"2021-07-14T17:42:47.889117Z","iopub.status.idle":"2021-07-14T17:42:48.302197Z","shell.execute_reply.started":"2021-07-14T17:42:47.889087Z","shell.execute_reply":"2021-07-14T17:42:48.301391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf # Work with tensors\nfrom tensorflow import keras # Framework for DL\nfrom tensorflow.keras import layers # Layers for NN\nimport missingno as msno # Tools for missing values\nfrom PIL import Image # Image Tool\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.applications import VGG16\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport os\n\nimport sys\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator\n#from keras.optimizers import adam, sgd, Adadelta \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.applications import VGG16, VGG19\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, ModelCheckpoint\nnp.random.seed(1000)\nimport warnings\nfrom keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, Convolution2D, MaxPooling2D\n\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.applications import VGG16,ResNet50,InceptionV3,MobileNet\nfrom keras import optimizers\nfrom keras.layers.core import Flatten, Dense, Dropout, Lambda\nfrom keras import layers\nfrom keras import models\nimport tensorflow as tf\nimport numpy as np\nimport time\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.applications import VGG16\nimport sys\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam \nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, Convolution2D, MaxPooling2D\nfrom keras import callbacks\n\nfrom keras import optimizers\nfrom keras.layers.core import Flatten, Dense, Dropout, Lambda\nfrom keras import layers\nfrom keras import models\nimport tensorflow as tf\nimport numpy as np\nimport time\n\nimport numpy as np\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras.backend as K\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:48.304744Z","iopub.execute_input":"2021-07-14T17:42:48.305027Z","iopub.status.idle":"2021-07-14T17:42:48.332206Z","shell.execute_reply.started":"2021-07-14T17:42:48.304999Z","shell.execute_reply":"2021-07-14T17:42:48.331314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_LIB = '../input/finding-lungs-in-ct-data/2d_images/'\nMASK_LIB = '../input/finding-lungs-in-ct-data/2d_masks/'\n\n\n#IMAGE_LIB = '../input/cvcclinicdb/TIF/Original/'\n#MASK_LIB = '../input/cvcclinicdb/TIF/Ground Truth/'","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:48.333974Z","iopub.execute_input":"2021-07-14T17:42:48.334319Z","iopub.status.idle":"2021-07-14T17:42:48.346769Z","shell.execute_reply.started":"2021-07-14T17:42:48.334286Z","shell.execute_reply":"2021-07-14T17:42:48.345882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nIMG_HEIGHT, IMG_WIDTH = 128, 128\nSEED=42\nepochs = 200\nbatchSize = 8\ninitial_learning_rate = 0.001\nsteps_per_epoch = 10\n\nearly_stop_patience = 50 #increase in the case that your model starts with very big learning rate\npatience_reduce_lr=20\nmin_lr=1e-12\n\"\"\"\n\n\"\"\"\n\n\n\n\n\n\nEpoch 00088: val_dice_coef did not improve from 0.55723\nEpoch 89/200\n10/10 [==============================] - 2s 226ms/step - loss: 0.4282 - precision_1: 0.9765 \n- recall_1: 0.9977 - auc_1: 0.9988 - accuracy: 0.9939 - dice_coef: 0.5705 - jacard: 0.3994 \n- val_loss: 0.4371 - val_precision_1: 0.9734 - val_recall_1: 0.9820 \n- val_auc_1: 0.9918 - val_accuracy: 0.9900 - val_dice_coef: 0.5613 \n- val_jacard: 0.3902\n\n\n\n\n\n\n\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:48.348483Z","iopub.execute_input":"2021-07-14T17:42:48.348867Z","iopub.status.idle":"2021-07-14T17:42:48.357635Z","shell.execute_reply.started":"2021-07-14T17:42:48.348834Z","shell.execute_reply":"2021-07-14T17:42:48.356727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_HEIGHT, IMG_WIDTH = 128, 128\nSEED=42\nepochs = 20 #200\nbatchSize = 4\ninitial_learning_rate = 0.001\nsteps_per_epoch = 100\n\nearly_stop_patience = 80 #increase in the case that your model starts with very big learning rate\npatience_reduce_lr=20\nmin_lr=1e-12","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:48.359167Z","iopub.execute_input":"2021-07-14T17:42:48.359568Z","iopub.status.idle":"2021-07-14T17:42:48.36945Z","shell.execute_reply.started":"2021-07-14T17:42:48.359535Z","shell.execute_reply":"2021-07-14T17:42:48.368702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_images = [x for x in sorted(os.listdir(IMAGE_LIB)) if x[-4:] == '.tif']\n\nx_data = np.empty((len(all_images), IMG_HEIGHT, IMG_WIDTH), dtype='float32')\nfor i, name in enumerate(all_images):\n    im = cv2.imread(IMAGE_LIB + name, cv2.IMREAD_UNCHANGED).astype(\"int16\").astype('float32')\n    im = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LANCZOS4)\n    im = (im - np.min(im)) / (np.max(im) - np.min(im))\n    x_data[i] = im\n\ny_data = np.empty((len(all_images), IMG_HEIGHT, IMG_WIDTH), dtype='float32')\nfor i, name in enumerate(all_images):\n    im = cv2.imread(MASK_LIB + name, cv2.IMREAD_UNCHANGED).astype('float32')/255.\n    im = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n    y_data[i] = im","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:48.372251Z","iopub.execute_input":"2021-07-14T17:42:48.372515Z","iopub.status.idle":"2021-07-14T17:42:49.91832Z","shell.execute_reply.started":"2021-07-14T17:42:48.372492Z","shell.execute_reply":"2021-07-14T17:42:49.917484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize = (8,4))\nax[0].imshow(x_data[0], cmap='gray')\nax[1].imshow(y_data[0], cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:49.921419Z","iopub.execute_input":"2021-07-14T17:42:49.921697Z","iopub.status.idle":"2021-07-14T17:42:50.155411Z","shell.execute_reply.started":"2021-07-14T17:42:49.921659Z","shell.execute_reply":"2021-07-14T17:42:50.154443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = x_data[:,:,:,np.newaxis]\ny_data = y_data[:,:,:,np.newaxis]\nx_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:50.158077Z","iopub.execute_input":"2021-07-14T17:42:50.158419Z","iopub.status.idle":"2021-07-14T17:42:50.172957Z","shell.execute_reply.started":"2021-07-14T17:42:50.158383Z","shell.execute_reply":"2021-07-14T17:42:50.172142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_generator(x_train, y_train, batch_size):\n    data_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(x_train, x_train, batch_size, seed=SEED)\n    \n    mask_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(y_train, y_train, batch_size, seed=SEED)\n    \n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:50.176072Z","iopub.execute_input":"2021-07-14T17:42:50.176325Z","iopub.status.idle":"2021-07-14T17:42:50.182402Z","shell.execute_reply.started":"2021-07-14T17:42:50.1763Z","shell.execute_reply":"2021-07-14T17:42:50.181579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_batch, mask_batch = next(my_generator(x_train, y_train, 8))\nfix, ax = plt.subplots(8,2, figsize=(8,20))\nfor i in range(8):\n    ax[i,0].imshow(image_batch[i,:,:,0])\n    ax[i,1].imshow(mask_batch[i,:,:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:50.183777Z","iopub.execute_input":"2021-07-14T17:42:50.184423Z","iopub.status.idle":"2021-07-14T17:42:51.411368Z","shell.execute_reply.started":"2021-07-14T17:42:50.184259Z","shell.execute_reply":"2021-07-14T17:42:51.410558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DCUnet===========================\n=======================================","metadata":{}},{"cell_type":"code","source":"\n\ndef conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n    '''\n    2D Convolutional layers\n    \n    Arguments:\n        x {keras layer} -- input layer \n        filters {int} -- number of filters\n        num_row {int} -- number of rows in filters\n        num_col {int} -- number of columns in filters\n    \n    Keyword Arguments:\n        padding {str} -- mode of padding (default: {'same'})\n        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n        activation {str} -- activation function (default: {'relu'})\n        name {str} -- name of the layer (default: {None})\n    \n    Returns:\n        [keras layer] -- [output layer]\n    '''\n\n    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n    x = BatchNormalization(axis=3, scale=False)(x)\n\n    if(activation == None):\n        return x\n\n    x = Activation(activation, name=name)(x)\n\n    return x\n\n\ndef trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n    '''\n    2D Transposed Convolutional layers\n    \n    Arguments:\n        x {keras layer} -- input layer \n        filters {int} -- number of filters\n        num_row {int} -- number of rows in filters\n        num_col {int} -- number of columns in filters\n    \n    Keyword Arguments:\n        padding {str} -- mode of padding (default: {'same'})\n        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n        name {str} -- name of the layer (default: {None})\n    \n    Returns:\n        [keras layer] -- [output layer]\n    '''\n\n    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n    x = BatchNormalization(axis=3, scale=False)(x)\n    \n    return x\n\n\ndef DCBlock(U, inp, alpha = 1.67):\n    '''\n    DC Block\n    \n    Arguments:\n        U {int} -- Number of filters in a corrsponding UNet stage\n        inp {keras layer} -- input layer \n    \n    Returns:\n        [keras layer] -- [output layer]\n    '''\n\n    W = alpha * U\n\n    #shortcut = inp\n\n    #shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) \n    # + int(W*0.5), 1, 1, activation=None, padding='same')\n\n    conv3x3_1 = conv2d_bn(inp, int(W*0.167), 3, 3, activation='relu', padding='same')\n\n    conv5x5_1 = conv2d_bn(conv3x3_1, int(W*0.333), 3, 3,activation='relu', padding='same')\n\n    conv7x7_1 = conv2d_bn(conv5x5_1, int(W*0.5), 3, 3,activation='relu', padding='same')\n\n    out1 = concatenate([conv3x3_1, conv5x5_1, conv7x7_1], axis=3)\n    out1 = BatchNormalization(axis=3)(out1)\n    \n    \n    \n    conv3x3_2 = conv2d_bn(inp, int(W*0.167), 3, 3, activation='relu', padding='same')\n\n    conv5x5_2 = conv2d_bn(conv3x3_2, int(W*0.333), 3, 3, activation='relu', padding='same')\n\n    conv7x7_2 = conv2d_bn(conv5x5_2, int(W*0.5), 3, 3, activation='relu', padding='same')\n    \n    out2 = concatenate([conv3x3_2, conv5x5_2, conv7x7_2], axis=3)\n    out2 = BatchNormalization(axis=3)(out2) \n    \n    \n    conv3x3_3 = conv2d_bn(inp, int(W*0.167), 3, 3, activation='relu', padding='same')\n\n    conv5x5_3 = conv2d_bn(conv3x3_3, int(W*0.333), 3, 3, activation='relu', padding='same')\n\n    conv7x7_3 = conv2d_bn(conv5x5_3, int(W*0.5), 3, 3, activation='relu', padding='same')\n    \n    out3 = concatenate([conv3x3_3, conv5x5_3, conv7x7_3], axis=3)\n    out3 = BatchNormalization(axis=3)(out3)\n    \n\n    out = add([out1, out2, out3])\n    out = Activation('relu')(out)\n    out = BatchNormalization(axis=3)(out)\n\n    return out\n\ndef ResPath(filters, length, inp):\n    '''\n    ResPath\n    \n    Arguments:\n        filters {int} -- [description]\n        length {int} -- length of ResPath\n        inp {keras layer} -- input layer \n    \n    Returns:\n        [keras layer] -- [output layer]\n    '''\n\n    shortcut = inp\n    shortcut = conv2d_bn(shortcut, filters, 1, 1,activation=None, padding='same')\n\n    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n\n    out = add([shortcut, out])\n    out = Activation('relu')(out)\n    out = BatchNormalization(axis=3)(out)\n\n    for i in range(length-1):\n\n        shortcut = out\n        shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n\n        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n\n        out = add([shortcut, out])\n        out = Activation('relu')(out)\n        out = BatchNormalization(axis=3)(out)\n\n    return out\n\n\n\n\ndef DCUNet(height, width, channels):\n    '''\n    DC-UNet\n    \n    Arguments:\n        height {int} -- height of image \n        width {int} -- width of image \n        n_channels {int} -- number of channels in image\n    \n    Returns:\n        [keras model] -- MultiResUNet model\n    '''\n\n    inputs = Input((height, width, channels))\n\n    dcblock1 = DCBlock(32, inputs)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(dcblock1)\n    dcblock1 = ResPath(32, 4, dcblock1)\n\n    dcblock2 = DCBlock(32*2, pool1)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(dcblock2)\n    dcblock2 = ResPath(32*2, 3, dcblock2)\n\n    dcblock3 = DCBlock(32*4, pool2)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(dcblock3)\n    dcblock3 = ResPath(32*4, 2, dcblock3)\n\n    dcblock4 = DCBlock(32*8, pool3)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(dcblock4)\n    dcblock4 = ResPath(32*8, 1, dcblock4)\n\n    dcblock5 = DCBlock(32*8, pool4)\n    pool5 = MaxPooling2D(pool_size=(2, 2))(dcblock5)\n    dcblock5 = ResPath(32*8, 1, dcblock5)\n    \n    dcblock6 = DCBlock(32*16, pool5)\n\n    up6 = concatenate([Conv2DTranspose(\n        32*8, (2, 2), strides=(2, 2), padding='same')(dcblock5), dcblock4], axis=3)\n    dcblock6 = DCBlock(32*8, up6)\n\n    up7 = concatenate([Conv2DTranspose(\n        32*4, (2, 2), strides=(2, 2), padding='same')(dcblock6), dcblock3], axis=3)\n    dcblock7 = DCBlock(32*4, up7)\n\n    up8 = concatenate([Conv2DTranspose(\n        32*2, (2, 2), strides=(2, 2), padding='same')(dcblock7), dcblock2], axis=3)\n    dcblock8 = DCBlock(32*2, up8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n        2, 2), padding='same')(dcblock8), dcblock1], axis=3)\n    dcblock9 = DCBlock(32, up9)\n\n    conv10 = conv2d_bn(dcblock9, 1, 1, 1, activation='sigmoid')\n    \n    model = Model(inputs=[inputs], outputs=[conv10])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:51.412724Z","iopub.execute_input":"2021-07-14T17:42:51.413214Z","iopub.status.idle":"2021-07-14T17:42:51.443098Z","shell.execute_reply.started":"2021-07-14T17:42:51.413176Z","shell.execute_reply":"2021-07-14T17:42:51.442207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"==============================================================================","metadata":{}},{"cell_type":"code","source":"#model = MultiResUnet(height=IMG_HEIGHT , width=IMG_WIDTH, n_channels=1)\n\nmodel = DCUNet(height=IMG_HEIGHT , width=IMG_WIDTH, channels=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:51.446123Z","iopub.execute_input":"2021-07-14T17:42:51.446394Z","iopub.status.idle":"2021-07-14T17:42:53.626893Z","shell.execute_reply.started":"2021-07-14T17:42:51.446371Z","shell.execute_reply":"2021-07-14T17:42:53.626078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=====================================================================================","metadata":{}},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\n# Descripcion del modelo\n#plot_model(model, show_shapes=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:53.628169Z","iopub.execute_input":"2021-07-14T17:42:53.628493Z","iopub.status.idle":"2021-07-14T17:42:53.634359Z","shell.execute_reply.started":"2021-07-14T17:42:53.62846Z","shell.execute_reply":"2021-07-14T17:42:53.633582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef saveModel(model):\n\n    model_json = model.to_json()\n\n    try:\n        os.makedirs('models')\n    except:\n        pass\n    \n    fp = open('models/modelP.json','w')\n    fp.write(model_json)\n    model.save('models/modelW.h5')\n\n\n\n#model.summary()\n#saveModel(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:53.635701Z","iopub.execute_input":"2021-07-14T17:42:53.636194Z","iopub.status.idle":"2021-07-14T17:42:53.642628Z","shell.execute_reply.started":"2021-07-14T17:42:53.636161Z","shell.execute_reply":"2021-07-14T17:42:53.640973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\n\n\n\"\"\"\ndef dice_coef(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n\n\"\"\"\n\n\n# different loss functions\ndef dice_coef(y_true, y_pred):\n    smooth = 1.0  #0.0\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef jacard(y_true, y_pred):\n\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum ( y_true_f * y_pred_f)\n    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n\n    return intersection/union\n\ndef dice_coef_loss(y_true,y_pred):\n    return 1 - dice_coef(y_true,y_pred)\n\ndef iou_loss(y_true,y_pred):\n    return 1 - jacard(y_true, y_pred)\n\ndef tversky(y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.75\n    smooth = 1\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\ndef focal_tversky(y_true,y_pred):\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)\n\n\n\n\ndef precision_xue(y_true, y_pred):\n    \"\"\"Precision metric.\n   Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n   \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\ndef recall_xue(y_true, y_pred):\n    \"\"\"Recall metric.\n    Only computes a batch-wise average of recall.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef f1_score(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:53.64536Z","iopub.execute_input":"2021-07-14T17:42:53.645858Z","iopub.status.idle":"2021-07-14T17:42:53.661812Z","shell.execute_reply.started":"2021-07-14T17:42:53.645821Z","shell.execute_reply":"2021-07-14T17:42:53.660743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n\n\nfrom keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    TP = tf.keras.metrics.TruePositives()\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = TP / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:53.663346Z","iopub.execute_input":"2021-07-14T17:42:53.6638Z","iopub.status.idle":"2021-07-14T17:42:53.676247Z","shell.execute_reply.started":"2021-07-14T17:42:53.663765Z","shell.execute_reply":"2021-07-14T17:42:53.675274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom sklearn.metrics import auc\n\n#initial_learning_rate=1e-3\nopt = Adam(lr=initial_learning_rate)\n\n#model.load_weights('./weights-unet.h5')\n\nmodel.compile(optimizer=opt, #loss='mse',\n              loss='binary_crossentropy',\n              #loss=focal_tversky, \n              metrics=[keras.metrics.Precision(), \n                       keras.metrics.Recall(), \n                       #keras.metrics.SpecificityAtSensitivity(0.5), \n                       #keras.metrics.SensitivityAtSpecificity(0.5),\n                       tf.keras.metrics.AUC(),\n                       #f1_score,\n                       'accuracy',          \n              ])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:53.677647Z","iopub.execute_input":"2021-07-14T17:42:53.678082Z","iopub.status.idle":"2021-07-14T17:42:53.711721Z","shell.execute_reply.started":"2021-07-14T17:42:53.678048Z","shell.execute_reply":"2021-07-14T17:42:53.711026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.callbacks import TensorBoard, ReduceLROnPlateau\nfrom keras.callbacks import ModelCheckpoint\n\n#output_weights_name='weights.h5'\nfilepath = '../working/weights-unet.h5'\n#TODO - VALIDATE THE LOGS OUTPUT\nlogs_base_dir = '../working/'\n#patience_reduce_lr=2\n#min_lr=1e-8\n#filepath = '../working/'\n\n\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,mode='min',\n                              patience=patience_reduce_lr, min_lr=min_lr, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=True,\n                                                 save_best_only=True, mode='max', period=1)\ncallbacks_conf = [checkpoint,\n             TensorBoard(log_dir=os.path.join(logs_base_dir, \"logs\"),\n                         batch_size=batchSize),\n             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_patience),\n             #tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1),\n             reduce_lr\n             \n            ]\n\n\"\"\"\n\n\n\nreduce_lr = ReduceLROnPlateau(monitor='val_dice_coef_loss', factor=0.1,mode='min',\n                              patience=patience_reduce_lr, min_lr=min_lr, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_dice_coef', verbose=1, save_weights_only=True,\n                                                 save_best_only=True, mode='max', period=1)\ncallbacks_conf = [checkpoint,\n             TensorBoard(log_dir=os.path.join(logs_base_dir, \"logs\"),\n                         batch_size=batchSize),\n             tf.keras.callbacks.EarlyStopping(monitor='val_dice_coef_loss', patience=early_stop_patience),\n             #tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1),\n             reduce_lr\n             \n            ]\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:53.713503Z","iopub.execute_input":"2021-07-14T17:42:53.714009Z","iopub.status.idle":"2021-07-14T17:42:54.0663Z","shell.execute_reply.started":"2021-07-14T17:42:53.713965Z","shell.execute_reply":"2021-07-14T17:42:54.065317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\nimport time\nstart = time.time()\n\n\n\nfit_history = model.fit(x=x_train, y=y_train, \n                        validation_data = (x_val, y_val),\n                        steps_per_epoch = steps_per_epoch,\n                        epochs = epochs,                       \n                        verbose = 1,\n                        callbacks=callbacks_conf,\n                       )\n\n\n\n#Calculate execution time\nend = time.time()\ndur = end - start\nif dur<60:\n    print(\"Execution Time:\",dur,\"seconds\")\nelif dur>60 and dur<3600:\n    dur=dur/60\n    print(\"Execution Time:\",dur,\"minutes\")\nelse:\n    dur=dur/(60*60)\n    print(\"Execution Time:\",dur,\"hours\")","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:42:54.067911Z","iopub.execute_input":"2021-07-14T17:42:54.06826Z","iopub.status.idle":"2021-07-14T17:45:00.801592Z","shell.execute_reply.started":"2021-07-14T17:42:54.068225Z","shell.execute_reply":"2021-07-14T17:45:00.800753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Epoch 00014: val_accuracy did not improve from 0.99154\nEpoch 15/20\n100/100 [==============================] - 2s 16ms/step - loss: 0.2414 - precision_1: 0.9934 - recall_1: 0.9843 - auc_1: 0.9993 - accuracy: 0.9947 - val_loss: 0.2367 - val_precision_1: 0.9899 - val_recall_1: 0.9728 - val_auc_1: 0.9948 - val_accuracy: 0.9917\n\nEpoch 00015: val_accuracy improved from 0.99154 to 0.99170, saving model to ../working/weights-unet.h5\nExecution Time: 2.1120710531870523 minutes","metadata":{}},{"cell_type":"code","source":"model.load_weights('../working/weights-unet.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:00.802918Z","iopub.execute_input":"2021-07-14T17:45:00.80327Z","iopub.status.idle":"2021-07-14T17:45:01.341512Z","shell.execute_reply.started":"2021-07-14T17:45:00.803232Z","shell.execute_reply":"2021-07-14T17:45:01.340387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\"\"\"\nplt.plot(hist.history['loss'], color='b')\nplt.plot(hist.history['val_loss'], color='r')\nplt.show()\nplt.plot(hist.history['dice_coef'], color='b')\nplt.plot(hist.history['val_dice_coef'], color='r')\nplt.show()\n\"\"\"\n\n\n\nplt.plot(fit_history.history[\"accuracy\"])\nplt.plot(fit_history.history[\"val_accuracy\"])\n#plt.plot(fit_history.history[\"val_auc_13\"])\n#plt.plot(fit_history.history[\"val_dice_coef\"])\n\nplt.plot(fit_history.history[\"loss\"])\nplt.plot(fit_history.history[\"val_loss\"])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\", \"loss\",\"Validation Loss\"])\nplt.show()\nplt.savefig('train_acc_val_plot.png')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:01.343702Z","iopub.execute_input":"2021-07-14T17:45:01.344031Z","iopub.status.idle":"2021-07-14T17:45:01.647102Z","shell.execute_reply.started":"2021-07-14T17:45:01.343995Z","shell.execute_reply":"2021-07-14T17:45:01.646282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(model.predict(x_train[0].reshape(1,IMG_HEIGHT, IMG_WIDTH, 1))[0,:,:,0], cmap='gray')\n\n#plt.imshow(model.predict(x_val[0].reshape(1,IMG_HEIGHT, IMG_WIDTH, 1))[0,:,:,0], cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:01.65087Z","iopub.execute_input":"2021-07-14T17:45:01.652989Z","iopub.status.idle":"2021-07-14T17:45:01.659624Z","shell.execute_reply.started":"2021-07-14T17:45:01.652946Z","shell.execute_reply":"2021-07-14T17:45:01.658524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Evaluation Functions\n\ndef saveModel(model):\n\n    model_json = model.to_json()\n\n    try:\n        os.makedirs('models')\n    except:\n        pass\n    \n    fp = open('models/modelP.json','w')\n    fp.write(model_json)\n    model.save('models/modelW.h5')\n\n\ndef evaluateModel(model, x_val, y_val, batchSize):\n    \n    try:\n        os.makedirs('results')\n    except:\n        pass \n\n    \n    yp = model.predict(x=x_val, batch_size=batchSize, verbose=1)\n    yp = np.round(yp,0)\n    \n    for i in range(10):\n\n        plt.figure(figsize=(20,10))\n        plt.subplot(1,3,1)\n        plt.imshow(x_val[i])\n        plt.title('Input')\n        plt.subplot(1,3,2)\n        plt.imshow(y_val[i].reshape(y_val[i].shape[0],y_val[i].shape[1]))\n        plt.title('Ground Truth')\n        plt.subplot(1,3,3)\n        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n        plt.title('Prediction')\n\n        intersection = yp[i].ravel() * y_val[i].ravel()\n        union = yp[i].ravel() + y_val[i].ravel() - intersection\n\n        jacard = (np.sum(intersection)/np.sum(union))  \n        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n\n        plt.savefig('results/'+str(i)+'.png',format='png')\n        plt.close()\n    \n    jacard = 0\n    dice = 0\n    \n    \n    for i in range(len(y_val)):\n        yp_2 = yp[i].ravel()\n        y2 = y_val[i].ravel()\n        \n        intersection = yp_2 * y2\n        union = yp_2 + y2 - intersection\n\n        jacard += (np.sum(intersection)/np.sum(union))  \n\n        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n        \n        \n\n    \n    jacard /= len(y_val)\n    dice /= len(y_val)\n    \n\n\n    print('Jacard Index : '+str(jacard))\n    print('Dice Coefficient : '+str(dice))\n    \n\n    fp = open('models/log.txt','a')\n    fp.write(str(jacard)+'\\n')\n    fp.close()\n\n    fp = open('models/best.txt','r')\n    best = fp.read()\n    fp.close()\n    \n\n    if(jacard>float(best)):\n        print('***********************************************')\n        #print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n        print('***********************************************')\n        fp = open('models/best.txt','w')\n        fp.write(str(jacard))\n        fp.close()\n        \n        saveModel(model)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:01.666355Z","iopub.execute_input":"2021-07-14T17:45:01.667045Z","iopub.status.idle":"2021-07-14T17:45:01.688914Z","shell.execute_reply.started":"2021-07-14T17:45:01.667005Z","shell.execute_reply":"2021-07-14T17:45:01.687942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntry:\n    os.makedirs('models')\nexcept:\n    pass\n    \nfp = open('models/log.txt','w')\nfp.close()\nfp = open('models/best.txt','w')\nfp.write('-1.0')\nfp.close()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:01.690661Z","iopub.execute_input":"2021-07-14T17:45:01.691269Z","iopub.status.idle":"2021-07-14T17:45:01.702733Z","shell.execute_reply.started":"2021-07-14T17:45:01.691224Z","shell.execute_reply":"2021-07-14T17:45:01.701786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModel(model,x_val, y_val,batchSize)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:01.704028Z","iopub.execute_input":"2021-07-14T17:45:01.704439Z","iopub.status.idle":"2021-07-14T17:45:09.297934Z","shell.execute_reply.started":"2021-07-14T17:45:01.704398Z","shell.execute_reply":"2021-07-14T17:45:09.296808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"14/14 [==============================] - 2s 18ms/step\nJacard Index : 0.9669314987129636\nDice Coefficient : 0.9816574248495278\n***********************************************\n***********************************************","metadata":{}},{"cell_type":"code","source":"# Show Predicted Samples\n\n\ni=0 #From\nz=10 #To\n\nyp = model.predict(x=x_val, batch_size=batchSize, verbose=1)\nyp = np.round(yp,0)\n\nfor i in range(z):\n\n        plt.figure(figsize=(20,10))\n        plt.subplot(1,3,1)\n        plt.imshow(x_val[i])\n        plt.title('Input')\n        plt.subplot(1,3,2)\n        plt.imshow(y_val[i].reshape(y_val[i].shape[0],y_val[i].shape[1]))\n        plt.title('Ground Truth')\n        plt.subplot(1,3,3)\n        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n        plt.title('Prediction')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:45:09.302976Z","iopub.execute_input":"2021-07-14T17:45:09.305323Z","iopub.status.idle":"2021-07-14T17:45:13.950232Z","shell.execute_reply.started":"2021-07-14T17:45:09.305277Z","shell.execute_reply":"2021-07-14T17:45:13.949246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}